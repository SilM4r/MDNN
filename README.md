**MDNN (My Deep Neural Network)**
==============

MDNN (My Deep Neural Network) je knihovna pro nÃ¡vrh a trÃ©novÃ¡nÃ­ neuronovÃ½ch sÃ­tÃ­ v jazyce C#. UmoÅ¾Åˆuje snadnou tvorbu a konfiguraci modelÅ¯ neuronovÃ½ch sÃ­tÃ­, jejich trÃ©novÃ¡nÃ­ a nÃ¡slednou integraci do projektÅ¯.

## ğŸ“š **Obsah**
- [ğŸ“Œ KlÃ­ÄovÃ© vlastnosti](#-klÃ­ÄovÃ©-vlastnosti)  
- [ğŸ›  Instalace](#-instalace)  
- [ğŸš€ RychlÃ½ start](#-rychlÃ½-start)  
- [âš™ Konfigurace modelu](#-konfigurace-modelu)  
- [ğŸ“Œ PÅ™idÃ¡vÃ¡nÃ­ vrstev do modelu](#-pÅ™idÃ¡vÃ¡nÃ­-vrstev-do-modelu)  
- [ğŸ¯ TrÃ©novÃ¡nÃ­ modelu](#-trÃ©novÃ¡nÃ­-modelu)  
- [â³ Optimalizace](#-optimalizace)
- [ğŸ“¦ ProdukÄnÃ­ nasazenÃ­](#-produkÄnÃ­-nasazenÃ­)


## ğŸ“Œ KlÃ­ÄovÃ© vlastnosti

- Podpora rÅ¯znÃ½ch typÅ¯ vrstev, vÄetnÄ›:
  - **Dense** (plnÄ› propojenÃ© vrstvy)
  - **MaxPooling**
  - **KonvoluÄnÃ­ neuronovÃ© sÃ­tÄ› (CNN)**
  - **RekurentnÃ­ neuronovÃ© sÃ­tÄ› (RNN)**
- MoÅ¾nost vyuÅ¾itÃ­ Å¡irokÃ© Å¡kÃ¡ly:
  - AktivaÄnÃ­ch funkcÃ­
  - OptimalizaÄnÃ­ch algoritmÅ¯
  - ZtrÃ¡tovÃ½ch funkcÃ­
- SnadnÃ¡ integrace do projektÅ¯ v C#
- Podpora akcelerace vÃ½poÄtÅ¯ pomocÃ­ GPU
- UklÃ¡dÃ¡nÃ­ a naÄÃ­tÃ¡nÃ­ modelÅ¯ ve formÃ¡tu JSON
- PÅ™eddefinovanÃ© trÃ©novacÃ­ smyÄky pro zjednoduÅ¡enÃ­ procesu trÃ©novÃ¡nÃ­

## ğŸ›  Instalace

MDNN je distribuovÃ¡na jako dynamickÃ¡ knihovna **MDNN.dll**. Pro jejÃ­ pouÅ¾itÃ­ je nutnÃ©:

1. PÅ™idat soubor **MDNN.dll** do projektu. (pÅ™idat novou zÃ¡vyslot do projektu)
2. Zahrnout pÅ™Ã­sluÅ¡nÃ© jmennÃ© prostory ve zdrojovÃ©m kÃ³du.

AlternativnÄ› lze stÃ¡hnout celÃ½ repozitÃ¡Å™ a spustit sestavenÃ­, kterÃ© automaticky vygeneruje novÃ½ soubor **MDNN.dll**.

## ğŸš€ RychlÃ½ start

NÃ­Å¾e je uveden jednoduchÃ½ pÅ™Ã­klad pouÅ¾itÃ­ knihovny MDNN pro vytvoÅ™enÃ­ a trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ›.

```csharp
using My_DNN.Layers;
using My_DNN.Layers.classes;
using My_DNN.Optimizers;
using My_DNN;
using My_DNN.Activation_functions;
using My_DNN.Loss_functions;

namespace MDNN_example
{
    internal class Program
    {
        static void Main(string[] args)
        {
            double[,] inputsDataset = new double[][] {...};  // VstupnÃ­ data
            double[,] outputDataset = new double[][] {...};  // OdpovÃ­dajÃ­cÃ­ vÃ½stupnÃ­ data

            Layer outputLayer = new Dense(1, new Linear());  // Konfigurace vÃ½stupnÃ­ vrstvy
            Optimizer optimizer = new SGD(0.01);  // NastavenÃ­ optimalizaÄnÃ­ho algoritmu
            Loss loss = new MSE();  // Definice ztrÃ¡tovÃ© funkce

            uint epoch = 1000;

            // Inicializace modelu
            MDNN model = new MDNN(outputLayer, optimizer, loss);
            model.Layers.Add(new Dense(1, new ReLu()));  // PÅ™idÃ¡nÃ­ skrytÃ© vrstvy

            Tensor tensorInputDataset = new Tensor(inputsDataset);
            Tensor tensorOutputDataset = new Tensor(outputDataset);

            // TrÃ©novÃ¡nÃ­ modelu
            model.Train.TrainLoop(tensorInputDataset, tensorOutputDataset, epoch, 1);
            
            // UloÅ¾enÃ­ modelu
            model.SaveAsJson("save");
        }
    }
}
```

## âš™ Konfigurace modelu

Knihovna **MDNN** umoÅ¾Åˆuje snadnÃ© nastavenÃ­ architektury neuronovÃ© sÃ­tÄ›, vÄetnÄ› vÃ½stupnÃ­ vrstvy, optimalizaÄnÃ­ho algoritmu a ztrÃ¡tovÃ© funkce.
Model je inicializovÃ¡n pomocÃ­ tÅ™Ã­dy **MDNN**, kterÃ¡ slouÅ¾Ã­ jako centrÃ¡lnÃ­ objekt pro manipulaci s neuronovou sÃ­tÃ­:
```csharp
MDNN model = new MDNN(outputLayer, optimizer, loss);
```
### Parametry konstruktoru

- **`outputLayer`** *(povinnÃ½ parametr)* â€“ objekt typu **Layer**, pÅ™edstavujÃ­cÃ­ vÃ½stupnÃ­ vrstvu sÃ­tÄ›.
- **`optimizer`** *(volitelnÃ½ parametr)* â€“ objekt typu **Optimizer**, kterÃ½ specifikuje optimalizaÄnÃ­ algoritmus. Pokud nenÃ­ zadÃ¡n, vÃ½chozÃ­ hodnota je **SGD(0.0001)**.
- **`loss`** *(volitelnÃ½ parametr)* â€“ objekt reprezentujÃ­cÃ­ ztrÃ¡tovou funkci. VÃ½chozÃ­ hodnota je **MSE()**.

podporovanÃ© optimizÃ©ry: SGD,ADAM,Momentum
podporovanÃ© zrÃ¡tovÃ© funkce: MSE, Cross Entropy

PÅ™Ã­padnÄ› knihovna podporuje i tvorbu vlastnÃ­ch optimalizÃ¡torÅ¯ a ztrÃ¡tovÃ½ch funkcÃ­ â€“ staÄÃ­ zdÄ›dit odpovÃ­dajÃ­cÃ­ mateÅ™skou tÅ™Ã­du napÅ™Ã­klad **`loss`**.

## ğŸ“Œ PÅ™idÃ¡vÃ¡nÃ­ vrstev do modelu
DalÅ¡Ã­ vrstvy lze do modelu pÅ™idÃ¡vat pomocÃ­ tÅ™Ã­dy **`Layers`**:

```csharp
model.Layers.Add(new Dense(64, new ReLu()));  // PÅ™idÃ¡nÃ­ skrytÃ© vrstvy s 64 neurony a ReLU aktivacÃ­
model.Layers.Add(new Dense(32, new Sigmoid()));  // DalÅ¡Ã­ vrstva s 32 neurony a sigmoid aktivacÃ­
```

KromÄ› funkce **`Add()`** obsahuje tÅ™Ã­da **`Layers`** takÃ© metody pro odebÃ­rÃ¡nÃ­ nebo pÅ™idÃ¡vÃ¡nÃ­ vrstev na konkrÃ©tnÃ­ pozici a Å™adu dalÅ¡Ã­ch funkcÃ­ pro manipulaci s vrstvami.
- **`Insert()`**
- **`RemoveAt()`**
- **`OutputLayerActivationFunc()`** - nastavÃ½ novou vÃ½stupnÃ­ aktivaÄnÃ­ funkci
- **`ClearAllLayersAndSetNewOutputLayer`** - vymaÅ¾e vÅ¡echny vrstvy a nastavÃ½ novou vÃ½stupnÃ­ vrstvu


Knihovna **MDNN** podporuje nÃ¡sledujÃ­cÃ­ vrstvy:
- `Dense()`
- `RNN()`
- `Conv()`
- `MaxPool()`
- WIP: transformer vrstva respektive attention Layer

V pÅ™Ã­padÄ› potÅ™eby lze vytvoÅ™it i vlastnÃ­ specializovanou vrstvu. StaÄÃ­ zdÄ›dit jednu z nÃ¡sledujÃ­cÃ­ch abstraktnÃ­ch tÅ™Ã­d:
- `Layer`
- `LayerBasedOnNeurons`
- `LayerWithUntrainedParameters`

PotÃ© je nutnÃ© implementovat vÅ¡echny jejich abstraktnÃ­ metody. Jakmile je novÃ¡ vrstva definovÃ¡na, lze ji pÅ™idat do modelu a pouÅ¾Ã­t pÅ™i trÃ©novÃ¡nÃ­.

## ğŸ¯ TrÃ©novÃ¡nÃ­ modelu
model se trÃ©nuje pomocÃ­ tÅ™Ã­dy Train, kterÃ¡ obsahuje veÅ¡kerÃ© potÅ™ebnÃ© metody pro Å™Ã­zenÃ­ trÃ©novÃ¡nÃ­. UÅ¾ivatel mÃ¡ moÅ¾nost volit mezi ÄtyÅ™mi metodami trÃ©novÃ¡nÃ­ podle poÅ¾adovanÃ© mÃ­ry kontroly nad uÄenÃ­m modelu. 
-	**`TrainLoop()`**
-	**`SimpleTrainLoop()`** 
-	**`Fit()`** a **`UpdateParams()`** 
-	**`BackPropagation()`** a **`FeedForward()`**


### **`TrainLoop()`**
Tato metoda pÅ™edstavuje hlavnÃ­ a zÃ¡roveÅˆ nejpokroÄilejÅ¡Ã­ trÃ©novacÃ­ proceduru v knihovnÄ›. Zahrnuje kompletnÃ­ trÃ©novacÃ­ smyÄku (train loop) a poskytuje nÃ¡sledujÃ­cÃ­ pokroÄilÃ© funkce:

- AutomatickÃ© uklÃ¡dÃ¡nÃ­ modelu s nejlepÅ¡Ã­ validacÃ­ (tzv. early stopping checkpoint).
- AutomatickÃ© mÃ­chÃ¡nÃ­ a rozdÄ›lenÃ­ datasetu na trÃ©novacÃ­, validaÄnÃ­ a testovacÃ­ ÄÃ¡sti.
- PrÅ¯bÄ›Å¾nÃ½ vÃ½pis informacÃ­ o prÅ¯bÄ›hu trÃ©novÃ¡nÃ­ (napÅ™. aktuÃ¡lnÃ­ epochy, metriky) do konzole.
- Detekce chyb, jako je vÃ½skyt hodnot typu NaN.
- AutomatickÃ© vykreslenÃ­ grafu prÅ¯bÄ›hu ztrÃ¡tovÃ© funkce (loss) napÅ™Ã­Ä epochami.

Parametry:
- **`Tensor inputs_values`** â€“ *povinnÃ½ parametr*  
  VstupnÃ­ dataset ve formÃ¡tu tenzoru. KaÅ¾dÃ½ Å™Ã¡dek odpovÃ­dÃ¡ jednomu trÃ©novacÃ­mu vzorku.

- **`Tensor current_output_values`** â€“ *povinnÃ½ parametr*  
  OdpovÃ­dajÃ­cÃ­ vÃ½stupy (labely) pro vstupnÃ­ data, rovnÄ›Å¾ ve formÃ¡tu tenzoru.

- **`uint number_of_epoch`** â€“ *povinnÃ½ parametr*  
  UrÄuje poÄet trÃ©novacÃ­ch epoch.

- **`uint size_of_mini_batch`** â€“ *nepovinnÃ½ parametr*  
  Velikost minibatche pouÅ¾Ã­vanÃ© bÄ›hem trÃ©novÃ¡nÃ­. Pokud nenÃ­ specifikovÃ¡no, pouÅ¾ije se vÃ½chozÃ­ hodnota `1`.

- **`bool isSequence`** â€“ *nepovinnÃ½ parametr*  
  Pokud je nastaveno na `true`, model bude oÄekÃ¡vat sekvenÄnÃ­ vstupnÃ­ data (napÅ™. ÄasovÃ© Å™ady, video nebo jinÃ¡ sekvenÄnÃ­ data). VÃ½chozÃ­ hodnota je `false`.

### **`SimpleTrainLoop()`**
JednÃ¡ se o zjednoduÅ¡enou verzi metody **`TrainLoop()`** Zahrnuje kompletnÃ­ trÃ©novacÃ­ smyÄku (train loop) a poskytuje nÃ¡sledujÃ­cÃ­ funkce:

- AutomatickÃ© uklÃ¡dÃ¡nÃ­ modelu s nejlepÅ¡Ã­ validacÃ­ (tzv. early stopping checkpoint).
- PrÅ¯bÄ›Å¾nÃ½ vÃ½pis informacÃ­ o prÅ¯bÄ›hu trÃ©novÃ¡nÃ­ (napÅ™. aktuÃ¡lnÃ­ epochy, metriky) do konzole.
- Detekce chyb, jako je vÃ½skyt hodnot typu NaN.

Parametry:
- **`double[][] inputs_values`** â€“ *povinnÃ½ parametr*  
  VstupnÃ­ dataset ve formÃ¡tu double[][]. KaÅ¾dÃ½ Å™Ã¡dek odpovÃ­dÃ¡ jednomu trÃ©novacÃ­mu vzorku.

- **`double[][] current_output_values`** â€“ *povinnÃ½ parametr*  
  OdpovÃ­dajÃ­cÃ­ vÃ½stupy (labely) pro vstupnÃ­ data, rovnÄ›Å¾ ve formÃ¡tu double[][].

- **`uint number_of_epoch`** â€“ *povinnÃ½ parametr*  
  UrÄuje poÄet trÃ©novacÃ­ch epoch.

- **`uint size_of_mini_batch`** â€“ *nepovinnÃ½ parametr*  
  Velikost minibatche pouÅ¾Ã­vanÃ© bÄ›hem trÃ©novÃ¡nÃ­. Pokud nenÃ­ specifikovÃ¡no, pouÅ¾ije se vÃ½chozÃ­ hodnota `1`.

### **`Fit()`** a **`UpdateParams()`** 
JednÃ¡ se o stÅ™ednÄ› pokroÄilÃ½ pÅ™Ã­stup k trÃ©novÃ¡nÃ­ modelÅ¯, kterÃ½ umoÅ¾Åˆuje implementaci vlastnÃ­ trÃ©novacÃ­ smyÄky (training loop). Tento pÅ™Ã­stup neposkytuje pÅ™edpÅ™ipravenÃ© funkcionality, avÅ¡ak uÅ¾ivatel mÃ¡ k dispozici sadu podpÅ¯rnÃ½ch tÅ™Ã­d, kterÃ© lze vyuÅ¾Ã­t pro vytvoÅ™enÃ­ doplÅˆkovÃ½ch komponent, jako je napÅ™Ã­klad vÃ½pis informacÃ­ o trÃ©novÃ¡nÃ­ do konzole, vizualizace trÃ©novacÃ­ch ztrÃ¡t pomocÃ­ grafÅ¯, nebo implementace testovacÃ­ch procedur pro vyhodnocenÃ­ modelu.

Tato metoda je tvoÅ™ena dvÄ›ma funkcemi: **`Fit()`** a **`UpdateParams()`**.  
Funkce **`Fit()`** provÃ¡dÃ­ jak vÃ½poÄet vÃ½stupu (tzv. *feedforward*), tak i zpÄ›tnou propagaci chyby (*backpropagation*), avÅ¡ak bez okamÅ¾itÃ© aktualizace modelovÃ½ch parametrÅ¯ â€“ mÃ­sto toho dochÃ¡zÃ­ k akumulaci gradientÅ¯.

Aktualizace parametrÅ¯ na zÃ¡kladÄ› akumulovanÃ½ch gradientÅ¯ je provedena aÅ¾ pÅ™i volÃ¡nÃ­ funkce **`UpdateParams()`**. Tento pÅ™Ã­stup odpovÃ­dÃ¡ trÃ©novÃ¡nÃ­ pomocÃ­ *minibatch*, kterÃ© mÅ¯Å¾e vÃ©st k efektivnÄ›jÅ¡Ã­mu a stabilnÄ›jÅ¡Ã­mu uÄenÃ­.

V pÅ™Ã­padÄ›, Å¾e uÅ¾ivatel nechce vyuÅ¾Ã­vat minibatch reÅ¾im, postaÄÃ­ volat obÄ› funkce bezprostÅ™ednÄ› po sobÄ›.

```csharp
 Random rnd = new Random();

 double[][] inputsDataset = new double[][] {...};  // input data 
 double[][] currentOutputDataset = new double[][] {...};  // currentOutput data 

 // Inicializace modelu
 MDNN model = new MDNN(new Dense(3), new Adam(0.001));

 // poÄet epoch a velikost minibatche
 int number_of_epoch = 5000;
 int size_of_miniBatch = 16;

 // poÄet vÅ¡ech prvkÅ¯ v datasetu 
 int number_of_element_intDataset = inputsDataset.Length;

 // hlavnÃ­ trÃ©novacÃ­ smyÄka
 for (int i = 0; i < number_of_epoch; i++)
 {
     // sekundÃ¡rnÃ­ smyÄka minibatch
     for (int j = 0; j < size_of_miniBatch; j++)
     {
         int num = rnd.Next(number_of_element_intDataset);

         double[] inputs = inputsDataset[num];
         double[] output = currentOutputDataset[num];

         // vÃ½poÄet na jednom konkrÃ©tnÃ­m prvku kterÃ½ je nÃ¡hodnÄ› zvolen z celÃ©ho datasetu
         model.Train.Fit(new Tensor(inputs),new Tensor(output));
     }

     // aktualizace trÃ©novacÃ­ch parametrÅ¯
     model.Train.UpdateParams();
 }

 // podpÅ¯rnÃ¡ funkce kterÃ¡ otestuje celÃ½ dataset na natrÃ©novanÃ©m datsetu
 model.Train.TestNeuralNetwork(new Tensor(Tensor.ConvertJaggedToMulti(inputsDataset)), new Tensor(Tensor.ConvertJaggedToMulti(currentOutputDataset)));
```
Parametry:
**`Fit()`** :
- **`Tensor inputs_values`** â€“ *povinnÃ½ parametr*  
  VstupnÃ­ dataset ve formÃ¡tu tenzoru. KaÅ¾dÃ½ Å™Ã¡dek odpovÃ­dÃ¡ jednomu trÃ©novacÃ­mu vzorku.

- **`Tensor target_values`** â€“ *povinnÃ½ parametr*  
  OdpovÃ­dajÃ­cÃ­ vÃ½stupy (labely) pro vstupnÃ­ data, rovnÄ›Å¾ ve formÃ¡tu tenzoru.

**`UpdateParams()`** - nemÃ¡ Å¾Ã¡dnÃ© paramtery

### **`BackPropagation()`** a **`FeedForward()`**
JednÃ¡ se o nejpokroÄilejÅ¡Ã­ metodu trÃ©novÃ¡nÃ­, kterÃ¡ poskytuje maximÃ¡lnÃ­ mÃ­ru kontroly nad jednotlivÃ½mi fÃ¡zemi uÄenÃ­. Na rozdÃ­l od pÅ™Ã­stupu vyuÅ¾Ã­vajÃ­cÃ­ho funkce **`Fit()`** a **`UpdateParams()`** je zde metoda **`Fit()`** rozdÄ›lena do dvou samostatnÃ½ch funkcÃ­: **`FeedForward()`** a **`BackPropagation()`**. Funkce **`FeedForward()`** provÃ¡dÃ­ dopÅ™ednÃ½ vÃ½poÄet neuronovÃ© sÃ­tÄ›, zatÃ­mco **`BackPropagation()`** zajiÅ¡Å¥uje zpÄ›tnou propagaci chyby a vÃ½poÄet gradientÅ¯. Tento pÅ™Ã­stup umoÅ¾Åˆuje detailnÃ­ manipulaci s jednotlivÃ½mi kroky trÃ©novacÃ­ho procesu, coÅ¾ je vhodnÃ© zejmÃ©na pro vÃ½zkumnÃ© ÃºÄely nebo pokroÄilÃ© optimalizace.

**UpozornÄ›nÃ­:** Pro samotnou aktualizaci modelovÃ½ch parametrÅ¯ je i v tomto pÅ™Ã­padÄ› nutnÃ© nÃ¡slednÄ› zavolat metodu **`UpdateParams()`**.

```csharp
 Random rnd = new Random();

 double[][] inputsDataset = new double[][] {...};  // input data 
 double[][] currentOutputDataset = new double[][] {...};  // currentOutput data 

 // Inicializace modelu
 MDNN model = new MDNN(new Dense(3), new Adam(0.001));

 // poÄet epoch a velikost minibatche
 int number_of_epoch = 5000;
 int size_of_miniBatch = 16;

 // poÄet vÅ¡ech prvkÅ¯ v datasetu 
 int number_of_element_intDataset = inputsDataset.Length;

 // hlavnÃ­ trÃ©novacÃ­ smyÄka
 for (int i = 0; i < number_of_epoch; i++)
 {
     // sekundÃ¡rnÃ­ smyÄka minibatch
     for (int j = 0; j < size_of_miniBatch; j++)
     {
         int num = rnd.Next(number_of_element_intDataset);

         double[] inputs = inputsDataset[num];
         double[] output = currentOutputDataset[num];

         // dopÅ™ednÃ½ vÃ½poÄet 
         model.Train.FeedForward(new Tensor(Tensor.ConvertJaggedToMulti(inputs)));

         // vÃ½poÄet gradientÅ¯ (podpÅ¯rnÃ¡ meotda)
         Tensor[] gradients = Gradient.GetGradients(new Tensor(Tensor.ConvertJaggedToMulti(inputs)), model);

         // zpÄ›tnÃ¡ propagace gradientÅ¯
         model.Train.BackPropagation(gradients);
     }

     // aktualizace trÃ©novacÃ­ch parametrÅ¯
     model.Train.UpdateParams();
 }

 // podpÅ¯rnÃ¡ funkce kterÃ¡ otestuje model na natrÃ©novanÃ©m datsetu
 model.Train.TestNeuralNetwork(new Tensor(Tensor.ConvertJaggedToMulti(inputsDataset)), new Tensor(Tensor.ConvertJaggedToMulti(currentOutputDataset)));
```
Parametry metod:

**`FeedForward()`**
- **`Tensor inputs_values`** â€“ *povinnÃ½ parametr*  
  VstupnÃ­ data ve formÃ¡tu tenzor.

**`BackPropagation()`**

Metoda **`BackPropagation()`** mÃ¡ dvÄ› pÅ™etÃ­Å¾enÃ­:

1. **PrvnÃ­ pÅ™etÃ­Å¾enÃ­:**
   - **`Tensor[] layer_gradients`** â€“ *povinnÃ½ parametr*  
     Pole gradientÅ¯ jednotlivÃ½ch vrstev ve formÃ¡tu tenzoru. SlouÅ¾Ã­ k ruÄnÄ› Å™Ã­zenÃ© zpÄ›tnÃ© propagaci.

2. **DruhÃ© pÅ™etÃ­Å¾enÃ­:**
   - **`Tensor target_values`** â€“ *povinnÃ½ parametr*  
     CÃ­lovÃ© vÃ½stupnÃ­ hodnoty odpovÃ­dajÃ­cÃ­ vstupnÃ­m datÅ¯m, rovnÄ›Å¾ ve formÃ¡tu tenzoru. V tomto pÅ™etÃ­Å¾enÃ­ metoda internÄ› spoÄÃ­tÃ¡ pÅ™Ã­sluÅ¡nÃ© hodnoty `layer_gradients`.

## â³ Optimalizace

Knihovna **MDNN** podporuje efektivnÃ­ optimalizaci vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ›. Mezi hlavnÃ­ optimalizaÄnÃ­ techniky patÅ™Ã­:
- **VyuÅ¾itÃ­ GPU** â€“ VÃ½poÄty neuronovÃ© sÃ­tÄ› lze provÃ¡dÄ›t na grafickÃ½ch procesorech, coÅ¾ vÃ½raznÄ› urychluje trÃ©novÃ¡nÃ­ modelÅ¯, zejmÃ©na pÅ™i prÃ¡ci s velkÃ½m mnoÅ¾stvÃ­m dat. Pro tento ÃºÄel byla vyvinuta vlastnÃ­ knihovna `gpu.dll`, kterÃ¡ je napsanÃ¡ v **C++** s vyuÅ¾itÃ­m **CUDA** a umoÅ¾Åˆuje efektivnÃ­ paralelnÃ­ vÃ½poÄty.
- **AsynchronnÃ­ vÃ½poÄty** â€“ Knihovna umoÅ¾Åˆuje plnÄ› asynchronnÃ­ zpracovÃ¡nÃ­ vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ›, coÅ¾ vede k efektivnÄ›jÅ¡Ã­mu vyuÅ¾itÃ­ vÃ½poÄetnÃ­ch zdrojÅ¯ a snÃ­Å¾enÃ­ latence bÄ›hem trÃ©novÃ¡nÃ­.

DÃ­ky tÄ›mto optimalizacÃ­m lze s MDNN efektivnÄ› trÃ©novat hlubokÃ© neuronovÃ© sÃ­tÄ› i na rozsÃ¡hlÃ½ch datovÃ½ch sadÃ¡ch.

### PoÅ¾adavky na vÃ½poÄty pÅ™es GPU

Pro umoÅ¾nÄ›nÃ­ vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ› na GPU je nutnÃ© stÃ¡hnout nÃ¡sledujÃ­cÃ­ komponenty:
- Knihovnu **`gpu.dll`**
- **CUDA Toolkit**

AktuÃ¡lnÄ› knihovna podporuje vÃ½poÄty pouze na **NVIDIA GPU**. Podpora pro **AMD** a **Intel** grafickÃ© karty je ve vÃ½voji.

### Aktivace vÃ½poÄtÅ¯ pÅ™es GPU

Pro zapnutÃ­ vÃ½poÄtu neuronovÃ© sÃ­tÄ› pÅ™es GPU lze pouÅ¾Ã­t nÃ¡sledujÃ­cÃ­ kÃ³d:
```csharp
GeneralNeuralNetworkSettings.calculationViaGpu = true;
```

### PouÅ¾itÃ­ asynchronnÃ­ch funkcÃ­

Knihovna podporuje asynchronnÃ­ zpracovÃ¡nÃ­ trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ›. UkÃ¡zka pouÅ¾itÃ­:
```csharp
await model.Train.TrainLoopAsync(tensorInputDataset, tensorOutputDataset, 1000);
```
KaÅ¾dÃ¡ synchronnÃ­ funkce mÃ¡ svou ekvivalentnÃ­ asynchronnÃ­ verzi, coÅ¾ umoÅ¾Åˆuje efektivnÃ­ paralelnÃ­ vÃ½poÄty.
napÅ™Ã­klad:

- **`TrainLoop()`**  -> **`TrainLoopAsync()`** 
- **`Fit()`**  -> **`FitAsync()`** 
- **`GetResults()`**  -> **`GetResultsAsync()`**

## ğŸ“¦ ProdukÄnÃ­ nasazenÃ­

Po dokonÄenÃ­ procesu trÃ©novÃ¡nÃ­ a uloÅ¾enÃ­ modelu ve formÃ¡tu JSON (napÅ™. pomocÃ­ metody `model.SaveAsJson("save")`) nÃ¡sleduje fÃ¡ze **produkÄnÃ­ho nasazenÃ­**. V tÃ©to fÃ¡zi je model integrovÃ¡n do cÃ­lovÃ© aplikace nebo systÃ©mu, kde slouÅ¾Ã­ k inference â€“ tedy k provÃ¡dÄ›nÃ­ predikcÃ­ na zÃ¡kladÄ› novÃ½ch vstupnÃ­ch dat.

### VyuÅ¾itÃ­ natrÃ©novanÃ©ho modelu

Pro pouÅ¾itÃ­ modelu v produkÄnÃ­m prostÅ™edÃ­ nenÃ­ tÅ™eba opÄ›tovnÃ© trÃ©novÃ¡nÃ­. StaÄÃ­ ho naÄÃ­st a nÃ¡slednÄ› na nÄ›j aplikovat vstupy:

```csharp
double[][] inputsDataset = new double[][] {...};  // input data 

MDNN model = MDNN.LoadModel("Completed training.json");

Tensor inputTensor = new Tensor(Tensor.ConvertJaggedToMulti(inputsDataset));

model.GetResults(inputTensor);
```






