**MDNN (My Deep Neural Network)**
==============

MDNN (My Deep Neural Network) je knihovna pro nÃ¡vrh a trÃ©novÃ¡nÃ­ neuronovÃ½ch sÃ­tÃ­ v jazyce C#. UmoÅ¾Åˆuje snadnou tvorbu a konfiguraci modelÅ¯ neuronovÃ½ch sÃ­tÃ­, jejich trÃ©novÃ¡nÃ­ a nÃ¡slednou integraci do projektÅ¯.

## ğŸ“š **Obsah**
- [ğŸ“Œ KlÃ­ÄovÃ© vlastnosti](#-klÃ­ÄovÃ©-vlastnosti)  
- [ğŸ›  Instalace](#-instalace)  
- [ğŸš€ RychlÃ½ start](#-rychlÃ½-start)  
- [âš™ Konfigurace modelu](#-konfigurace-modelu)  
- [ğŸ“Œ PÅ™idÃ¡vÃ¡nÃ­ vrstev do modelu](#-pÅ™idÃ¡vÃ¡nÃ­-vrstev-do-modelu)  
- [ğŸ¯ TrÃ©novÃ¡nÃ­ modelu](#-trÃ©novÃ¡nÃ­-modelu)  
- [â³ Optimalizace](#-optimalizace)
- [ğŸ“¦ ProdukÄnÃ­ nasazenÃ­](#-produkÄnÃ­-nasazenÃ­)


## ğŸ“Œ KlÃ­ÄovÃ© vlastnosti

- Podpora rÅ¯znÃ½ch typÅ¯ vrstev, vÄetnÄ›:
  - **Dense** (plnÄ› propojenÃ© vrstvy)
  - **MaxPooling**
  - **KonvoluÄnÃ­ neuronovÃ© sÃ­tÄ› (CNN)**
  - **RekurentnÃ­ neuronovÃ© sÃ­tÄ› (RNN)**
- MoÅ¾nost vyuÅ¾itÃ­ Å¡irokÃ© Å¡kÃ¡ly:
  - AktivaÄnÃ­ch funkcÃ­
  - OptimalizaÄnÃ­ch algoritmÅ¯
  - ZtrÃ¡tovÃ½ch funkcÃ­
- SnadnÃ¡ integrace do projektÅ¯ v C#
- Podpora akcelerace vÃ½poÄtÅ¯ pomocÃ­ GPU
- UklÃ¡dÃ¡nÃ­ a naÄÃ­tÃ¡nÃ­ modelÅ¯ ve formÃ¡tu JSON
- PÅ™eddefinovanÃ© trÃ©novacÃ­ smyÄky pro zjednoduÅ¡enÃ­ procesu trÃ©novÃ¡nÃ­

## ğŸ›  Instalace

MDNN je distribuovÃ¡na jako dynamickÃ¡ knihovna **MDNN.dll**. Pro jejÃ­ pouÅ¾itÃ­ je nutnÃ©:

1. PÅ™idat soubor **MDNN.dll** do projektu.
2. Zahrnout pÅ™Ã­sluÅ¡nÃ© jmennÃ© prostory ve zdrojovÃ©m kÃ³du.

AlternativnÄ› lze stÃ¡hnout celÃ½ repozitÃ¡Å™ a spustit sestavenÃ­, kterÃ© automaticky vygeneruje novÃ½ soubor **MDNN.dll**.

## ğŸš€ RychlÃ½ start

NÃ­Å¾e je uveden jednoduchÃ½ pÅ™Ã­klad pouÅ¾itÃ­ knihovny MDNN pro vytvoÅ™enÃ­ a trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ›.

```csharp
using My_DNN.Layers;
using My_DNN.Layers.classes;
using My_DNN.Optimizers;
using My_DNN;
using My_DNN.Activation_functions;
using My_DNN.Loss_functions;

namespace MDNN_example
{
    internal class Program
    {
        static void Main(string[] args)
        {
            double[,] inputsDataset = new double[][] {...};  // VstupnÃ­ data
            double[,] outputDataset = new double[][] {...};  // OdpovÃ­dajÃ­cÃ­ vÃ½stupnÃ­ data

            Layer outputLayer = new Dense(1, new Linear());  // Konfigurace vÃ½stupnÃ­ vrstvy
            Optimizer optimizer = new SGD(0.01);  // NastavenÃ­ optimalizaÄnÃ­ho algoritmu
            Loss loss = new MSE();  // Definice ztrÃ¡tovÃ© funkce

            uint epoch = 1000;

            // Inicializace modelu
            MDNN model = new MDNN(outputLayer, optimizer, loss);
            model.Layers.Add(new Dense(1, new ReLu()));  // PÅ™idÃ¡nÃ­ skrytÃ© vrstvy

            Tensor tensorInputDataset = new Tensor(inputsDataset);
            Tensor tensorOutputDataset = new Tensor(outputDataset);

            // TrÃ©novÃ¡nÃ­ modelu
            model.Train.TrainLoop(tensorInputDataset, tensorOutputDataset, epoch, 1);
            
            // UloÅ¾enÃ­ modelu
            model.SaveAsJson("save");
        }
    }
}
```

## âš™ Konfigurace modelu

Knihovna **MDNN** umoÅ¾Åˆuje snadnÃ© nastavenÃ­ architektury neuronovÃ© sÃ­tÄ›, vÄetnÄ› vÃ½stupnÃ­ vrstvy, optimalizaÄnÃ­ho algoritmu a ztrÃ¡tovÃ© funkce.
Model je inicializovÃ¡n pomocÃ­ tÅ™Ã­dy **MDNN**, kterÃ¡ slouÅ¾Ã­ jako centrÃ¡lnÃ­ objekt pro manipulaci s neuronovou sÃ­tÃ­:
```csharp
MDNN model = new MDNN(outputLayer, optimizer, loss);
```
## Parametry konstruktoru

- **`outputLayer`** *(povinnÃ½ parametr)* â€“ objekt typu **Layer**, pÅ™edstavujÃ­cÃ­ vÃ½stupnÃ­ vrstvu sÃ­tÄ›.
- **`optimizer`** *(volitelnÃ½ parametr)* â€“ objekt typu **Optimizer**, kterÃ½ specifikuje optimalizaÄnÃ­ algoritmus. Pokud nenÃ­ zadÃ¡n, vÃ½chozÃ­ hodnota je **SGD(0.0001)**.
- **`loss`** *(volitelnÃ½ parametr)* â€“ objekt reprezentujÃ­cÃ­ ztrÃ¡tovou funkci. VÃ½chozÃ­ hodnota je **MSE()**.

podporovanÃ© optimizÃ©ry: SGD,ADAM,Momentum
podporovanÃ© zrÃ¡tovÃ© funkce: MSE, Cross Entropy

PÅ™Ã­padnÄ› knihovna podporuje i tvorbu vlastnÃ­ch optimalizÃ¡torÅ¯ a ztrÃ¡tovÃ½ch funkcÃ­ â€“ staÄÃ­ zdÄ›dit odpovÃ­dajÃ­cÃ­ mateÅ™skou tÅ™Ã­du napÅ™Ã­klad **`loss`**.

## ğŸ“Œ PÅ™idÃ¡vÃ¡nÃ­ vrstev do modelu
DalÅ¡Ã­ vrstvy lze do modelu pÅ™idÃ¡vat pomocÃ­ tÅ™Ã­dy **`Layers`**:

```csharp
model.Layers.Add(new Dense(64, new ReLu()));  // PÅ™idÃ¡nÃ­ skrytÃ© vrstvy s 64 neurony a ReLU aktivacÃ­
model.Layers.Add(new Dense(32, new Sigmoid()));  // DalÅ¡Ã­ vrstva s 32 neurony a sigmoid aktivacÃ­
```

KromÄ› funkce **`Add()`** obsahuje tÅ™Ã­da **`Layers`** takÃ© metody pro odebÃ­rÃ¡nÃ­ nebo pÅ™idÃ¡vÃ¡nÃ­ vrstev na konkrÃ©tnÃ­ pozici a Å™adu dalÅ¡Ã­ch funkcÃ­ pro manipulaci s vrstvami.

Knihovna **MDNN** podporuje nÃ¡sledujÃ­cÃ­ vrstvy:
- `Dense()`
- `RNN()`
- `Conv()`
- `MaxPool()`
- WIP: transformer vrstva respektive attention Layer

V pÅ™Ã­padÄ› potÅ™eby lze vytvoÅ™it i vlastnÃ­ specializovanou vrstvu. StaÄÃ­ zdÄ›dit jednu z nÃ¡sledujÃ­cÃ­ch abstraktnÃ­ch tÅ™Ã­d:
- `Layer`
- `LayerBasedOnNeurons`
- `LayerWithUntrainedParameters`

PotÃ© je nutnÃ© implementovat vÅ¡echny jejich abstraktnÃ­ metody. Jakmile je novÃ¡ vrstva definovÃ¡na, lze ji pÅ™idat do modelu a pouÅ¾Ã­t pÅ™i trÃ©novÃ¡nÃ­.

## ğŸ¯ TrÃ©novÃ¡nÃ­ modelu
model se trÃ©nuje pomocÃ­ tÅ™Ã­dy Train, kterÃ¡ obsahuje veÅ¡kerÃ© potÅ™ebnÃ© metody pro Å™Ã­zenÃ­ trÃ©novÃ¡nÃ­. UÅ¾ivatel mÃ¡ moÅ¾nost volit mezi ÄtyÅ™mi metodami trÃ©novÃ¡nÃ­ podle poÅ¾adovanÃ© mÃ­ry kontroly nad uÄenÃ­m modelu. 
-	**`TrainLoop()`**
-	**`SimpleTrainLoop()`** 
-	**`Fit() a UpdateParams()`** 
-	**`BackPropagation() a FeedForward()`**


### **`TrainLoop()`**
Tato funkce pÅ™edstavuje hlavnÃ­ a zÃ¡roveÅˆ nejpokroÄilejÅ¡Ã­ trÃ©novacÃ­ proceduru v knihovnÄ›. Zahrnuje kompletnÃ­ trÃ©novacÃ­ smyÄku (train loop) a poskytuje nÃ¡sledujÃ­cÃ­ pokroÄilÃ© funkce:

- AutomatickÃ© uklÃ¡dÃ¡nÃ­ modelu s nejlepÅ¡Ã­ validacÃ­ (tzv. early stopping checkpoint).
- AutomatickÃ© mÃ­chÃ¡nÃ­ a rozdÄ›lenÃ­ datasetu na trÃ©novacÃ­, validaÄnÃ­ a testovacÃ­ ÄÃ¡sti.
- PrÅ¯bÄ›Å¾nÃ½ vÃ½pis informacÃ­ o prÅ¯bÄ›hu trÃ©novÃ¡nÃ­ (napÅ™. aktuÃ¡lnÃ­ epochy, metriky) do konzole.
- Detekce chyb, jako je vÃ½skyt hodnot typu NaN.
- AutomatickÃ© vykreslenÃ­ grafu prÅ¯bÄ›hu ztrÃ¡tovÃ© funkce (loss) napÅ™Ã­Ä epochami.

Parametry:
- **`Tensor inputs_values`** â€“ *povinnÃ½ parametr*  
  VstupnÃ­ dataset ve formÃ¡tu tenzoru. KaÅ¾dÃ½ Å™Ã¡dek odpovÃ­dÃ¡ jednomu trÃ©novacÃ­mu vzorku.

- **`Tensor current_output_values`** â€“ *povinnÃ½ parametr*  
  OdpovÃ­dajÃ­cÃ­ vÃ½stupy (labely) pro vstupnÃ­ data, rovnÄ›Å¾ ve formÃ¡tu tenzoru.

- **`uint number_of_epoch`** â€“ *povinnÃ½ parametr*  
  UrÄuje poÄet trÃ©novacÃ­ch epoch.

- **`uint size_of_mini_batch`** â€“ *nepovinnÃ½ parametr*  
  Velikost minibatche pouÅ¾Ã­vanÃ© bÄ›hem trÃ©novÃ¡nÃ­. Pokud nenÃ­ specifikovÃ¡no, pouÅ¾ije se vÃ½chozÃ­ hodnota `1`.

- **`bool isSequence`** â€“ *nepovinnÃ½ parametr*  
  Pokud je nastaveno na `true`, model bude oÄekÃ¡vat sekvenÄnÃ­ vstupnÃ­ data (napÅ™. ÄasovÃ© Å™ady, video nebo jinÃ¡ sekvenÄnÃ­ data). VÃ½chozÃ­ hodnota je `false`.

## â³ Optimalizace

Knihovna **MDNN** podporuje efektivnÃ­ optimalizaci vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ›. Mezi hlavnÃ­ optimalizaÄnÃ­ techniky patÅ™Ã­:
- **VyuÅ¾itÃ­ GPU** â€“ VÃ½poÄty neuronovÃ© sÃ­tÄ› lze provÃ¡dÄ›t na grafickÃ½ch procesorech, coÅ¾ vÃ½raznÄ› urychluje trÃ©novÃ¡nÃ­ modelÅ¯, zejmÃ©na pÅ™i prÃ¡ci s velkÃ½m mnoÅ¾stvÃ­m dat. Pro tento ÃºÄel byla vyvinuta vlastnÃ­ knihovna `gpu.dll`, kterÃ¡ je napsanÃ¡ v **C++** s vyuÅ¾itÃ­m **CUDA** a umoÅ¾Åˆuje efektivnÃ­ paralelnÃ­ vÃ½poÄty.
- **AsynchronnÃ­ vÃ½poÄty** â€“ Knihovna umoÅ¾Åˆuje plnÄ› asynchronnÃ­ zpracovÃ¡nÃ­ vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ›, coÅ¾ vede k efektivnÄ›jÅ¡Ã­mu vyuÅ¾itÃ­ vÃ½poÄetnÃ­ch zdrojÅ¯ a snÃ­Å¾enÃ­ latence bÄ›hem trÃ©novÃ¡nÃ­.

DÃ­ky tÄ›mto optimalizacÃ­m lze s MDNN efektivnÄ› trÃ©novat hlubokÃ© neuronovÃ© sÃ­tÄ› i na rozsÃ¡hlÃ½ch datovÃ½ch sadÃ¡ch.

### PoÅ¾adavky na vÃ½poÄty pÅ™es GPU

Pro umoÅ¾nÄ›nÃ­ vÃ½poÄtÅ¯ neuronovÃ© sÃ­tÄ› na GPU je nutnÃ© stÃ¡hnout nÃ¡sledujÃ­cÃ­ komponenty:
- Knihovnu **`gpu.dll`**
- **CUDA Toolkit**

AktuÃ¡lnÄ› knihovna podporuje vÃ½poÄty pouze na **NVIDIA GPU**. Podpora pro **AMD** a **Intel** grafickÃ© karty je ve vÃ½voji.

### Aktivace vÃ½poÄtÅ¯ pÅ™es GPU

Pro zapnutÃ­ vÃ½poÄtu neuronovÃ© sÃ­tÄ› pÅ™es GPU lze pouÅ¾Ã­t nÃ¡sledujÃ­cÃ­ kÃ³d:
```csharp
GeneralNeuralNetworkSettings.calculationViaGpu = true;
```

### PouÅ¾itÃ­ asynchronnÃ­ch funkcÃ­

Knihovna podporuje asynchronnÃ­ zpracovÃ¡nÃ­ trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ›. UkÃ¡zka pouÅ¾itÃ­:
```csharp
await model.Train.TrainLoopAsync(tensorInputDataset, tensorOutputDataset, 1000);
```
KaÅ¾dÃ¡ synchronnÃ­ funkce mÃ¡ svou ekvivalentnÃ­ asynchronnÃ­ verzi, coÅ¾ umoÅ¾Åˆuje efektivnÃ­ paralelnÃ­ vÃ½poÄty.
napÅ™Ã­klad:

- **`TrainLoop()`**  -> **`TrainLoopAsync()`** 
- **`Fit()`**  -> `** FitAsync()`** 
- **`GetResults()`**  -> **`GetResultsAsync()`**

## ğŸ“¦ ProdukÄnÃ­ nasazenÃ­

Po dokonÄenÃ­ procesu trÃ©novÃ¡nÃ­ a uloÅ¾enÃ­ modelu ve formÃ¡tu JSON (napÅ™. pomocÃ­ metody `model.SaveAsJson("save")`) nÃ¡sleduje fÃ¡ze **produkÄnÃ­ho nasazenÃ­**. V tÃ©to fÃ¡zi je model integrovÃ¡n do cÃ­lovÃ© aplikace nebo systÃ©mu, kde slouÅ¾Ã­ k inference â€“ tedy k provÃ¡dÄ›nÃ­ predikcÃ­ na zÃ¡kladÄ› novÃ½ch vstupnÃ­ch dat.

### ğŸ§  VyuÅ¾itÃ­ natrÃ©novanÃ©ho modelu

Pro pouÅ¾itÃ­ modelu v produkÄnÃ­m prostÅ™edÃ­ nenÃ­ tÅ™eba opÄ›tovnÃ© trÃ©novÃ¡nÃ­. StaÄÃ­ ho naÄÃ­st a nÃ¡slednÄ› na nÄ›j aplikovat vstupy:

```csharp
double[][] inputsDataset = new double[][] {...};  // input data 

MDNN model = MDNN.LoadModel("Completed training.json");

Tensor inputTensor = new Tensor(Tensor.ConvertJaggedToMulti(inputsDataset));

model.GetResults(inputTensor);
```






